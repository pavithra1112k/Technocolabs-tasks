{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA0F8qas0xx3"
   },
   "source": [
    "# Problem Definition\n",
    "#### How to determine the *price* of a used car?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ra3KF3e00xyI"
   },
   "source": [
    "## Contents\n",
    "\n",
    "[Installation Setup](#Installation-Setup) <br>\n",
    "+   [Environment Config](#Environment-Configuration) <br>\n",
    "+   [Python Packages](#Loading-Packages) <br>\n",
    "+   [Apache Spark](#Creating-SparkSession) <br>\n",
    "\n",
    "[Extract, Transform, Load](#Extract-Stage) <br>\n",
    "This includes the various stages of the ETL Pipeline <br>\n",
    "+   [Extract](#Extract-Stage) <br>\n",
    "    +   [Kaggle Dataset](#Kaggle-Dataset) <br>\n",
    "    +   [Validating Data](#Validating-Data) <br>\n",
    "    +   [Cleaning Data (Basic)](#Cleaning-Data-(Basic)) <br>\n",
    "    +   [Caching Data on S3](#Caching-Extract-Data-on-S3) <br>\n",
    "+   [Transform](#Transform-Stage) <br>\n",
    "    +   [Cleaning Data](#Cleaning-Data) <br>\n",
    "    +   [Feature Engineering](#Feature-Engineering) <br>\n",
    "    +   [Sampling Data](#Sampling-Data) <br>\n",
    "    +   [Exploratory Data Analysis using Pandas, Matplotlib and Seaborn](#Exploratory-Data-Analysis) <br>\n",
    "    +   [Caching Data on S3](#Caching-Transform-Data-on-S3) <br>\n",
    "+   [Load](#Load-Stage) <br>\n",
    "    +   [Preprocessing Data for Learning Model](#Load-Data)\n",
    "    +   [Migrate Data to Database](#Load-Data)\n",
    "    \n",
    "[Predicting Used Car Price](#Machine-Learning)\n",
    "+   Implementing Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29_3tTeK0xyK"
   },
   "source": [
    "# Installation Setup\n",
    "\n",
    "## Tool Versions\n",
    "\n",
    "```\n",
    "Apache Spark - 2.4.3\n",
    "Jupyter Notebook - 4.4.0\n",
    "```\n",
    "    \n",
    "## Environment Configuration\n",
    "\n",
    "#### Configuring ~/.bash_profile\n",
    "\n",
    "```\n",
    "export PATH=\"/usr/local/bin:$PATH\"\n",
    "PATH=\"/Library/Frameworks/Python.framework/Versions/3.7/bin:${PATH}\"\n",
    "export PATH=/usr/local/scala/bin:$PATH\n",
    "export PATH=/usr/local/spark/bin:$PATH\n",
    "export JAVA_HOME=$(/usr/libexec/java_home -v 1.8)\n",
    "export PYSPARK_PYTHON=python3.7\n",
    "```\n",
    "\n",
    "#### Configuring ~/.bashrc\n",
    "\n",
    "```\n",
    "export PYSPARK_PYTHON=/usr/local/bin/python3.7\n",
    "export PYSPARK_DRIVER_PYTHON=/usr/local/bin/python3.7\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWOHVc9b0xyN"
   },
   "source": [
    "### Findspark\n",
    "\n",
    "Use `findspark` to be able to find and import **Pyspark** module, while correctly setting environmental variables and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WGbZXTSn0xyO"
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "import findspark\n",
    "try:\n",
    "    findspark.init('C:\\Spark\\spark-3.2.1-bin-hadoop2.7\\spark-3.2.1-bin-hadoop2.7')\n",
    "except:\n",
    "    print (\"Error:\", ''.join(traceback.format_stack()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQBrmPHN0xyS"
   },
   "source": [
    "Check paths before Executing PySpark Session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PvmmtV6s0xyT",
    "outputId": "2da53510-e0a3-41a9-cf9c-e80eee446c9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH: C:\\Users\\Teja Tetali\\Anaconda;C:\\Users\\Teja Tetali\\Anaconda\\Library\\mingw-w64\\bin;C:\\Users\\Teja Tetali\\Anaconda\\Library\\usr\\bin;C:\\Users\\Teja Tetali\\Anaconda\\Library\\bin;C:\\Users\\Teja Tetali\\Anaconda\\Scripts;C:\\Users\\Teja Tetali\\Anaconda\\bin;C:\\Users\\Teja Tetali\\Anaconda\\condabin;C:\\Users\\Teja Tetali\\Anaconda;C:\\Users\\Teja Tetali\\Anaconda\\Library\\mingw-w64\\bin;C:\\Users\\Teja Tetali\\Anaconda\\Library\\usr\\bin;C:\\Users\\Teja Tetali\\Anaconda\\Library\\bin;C:\\Users\\Teja Tetali\\Anaconda\\Scripts;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Users\\Teja Tetali\\AppData\\Local\\Programs\\Python\\Python310\\Scripts;C:\\Users\\Teja Tetali\\AppData\\Local\\Programs\\Python\\Python310;C:\\Program Files\\Python310\\Scripts;C:\\Program Files\\Python310;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\Program Files\\Cloudflare\\Cloudflare WARP;C:\\Program Files\\Java\\jdk1.8.0_321\\bin;C:\\Python27;C:\\Python27\\Scripts;C:\\Program Files\\Java\\jdk1.8.0_321\\bin;C:\\Cassandra\\apache-cassandra-3.11.12-bin\\apache-cassandra-3.11.12\\bin;C:\\Program Files\\dotnet;C:\\Users\\Teja Tetali\\AppData\\Local\\Programs\\Python\\Python37-32\\Scripts;C:\\Users\\Teja Tetali\\AppData\\Local\\Programs\\Python\\Python37-32;C:\\Users\\Teja Tetali\\AppData\\Local\\Microsoft\\WindowsApps;.;C:\\Users\\Teja Tetali\\AppData\\Local\\Programs\\Microsoft VS Code\\bin\n",
      "\n",
      "SPARK_HOME: C:\\Spark\\spark-3.2.1-bin-hadoop2.7\\spark-3.2.1-bin-hadoop2.7\n",
      "PYSPARK_PYTHON: C:\\Users\\Teja Tetali\\Anaconda\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(\"PATH: %s\\n\" % os.environ['PATH'])\n",
    "print(\"SPARK_HOME: %s\" % os.environ['SPARK_HOME'])\n",
    "print(\"PYSPARK_PYTHON: %s\" % os.environ['PYSPARK_PYTHON'])\n",
    "#print(\"PYSPARK_DRIVER_PYTHON: %s\" % os.environ['PYSPARK_DRIVER_PYTHON'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTfCr1iO0xyX"
   },
   "source": [
    "## Loading Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9LiA1Vg40xyZ"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "from pyspark.sql.functions import *\n",
    "from functools import reduce\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJeEQLZS0xyc"
   },
   "source": [
    "### Package Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iWxahSHD0xyg",
    "outputId": "2b1c2cef-2ac7-4a4d-ff5b-ea7a0d3f809d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.3.4\n",
      "numpy: 1.20.3\n",
      "matplotlib: 3.4.3\n",
      "seaborn: 0.11.2\n",
      "Python: 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('seaborn: {}'.format(sns.__version__))\n",
    "print('Python: {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHzKRc-T0xyh"
   },
   "source": [
    "## Creating SparkSession\n",
    "Get package to handle AWS to access S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rHm1Wxfa0xyi",
    "outputId": "0d980318-f337-4e4d-b52d-8b95f120b2ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYSPARK_SUBMIT_ARGS=--packages=org.apache.hadoop:hadoop-aws:2.7.3 pyspark-shell\n"
     ]
    }
   ],
   "source": [
    "%set_env PYSPARK_SUBMIT_ARGS=--packages=org.apache.hadoop:hadoop-aws:2.7.3 pyspark-shell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHXcJDak0xyj"
   },
   "source": [
    "Creating Spark Session, hosted across all local nodes on a **Standalone Cluster**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cNM6PIzD0xyk"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"PySpark Craigslist\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZW0qxIFk0xyl"
   },
   "source": [
    "Configure Hadoop connection for S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uaIwbr8M0xym"
   },
   "outputs": [],
   "source": [
    "hadoopConf=spark.sparkContext._jsc.hadoopConfiguration()\n",
    "hadoopConf.set(\"fs.s3a.access.key\", \"AKIAQQADETG4J56SFQIV\")\n",
    "hadoopConf.set(\"fs.s3a.secret.key\", \"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzlBFhY20xym"
   },
   "source": [
    "Monitoring Spark instrumentation through the WebUI available through `localhost:4040/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wQnXfmF0xyn"
   },
   "source": [
    "# Extract Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9NHyykv0xyo"
   },
   "source": [
    "## Project Dataset\n",
    "\n",
    "Available [https://www.truecar.com/used-cars-for-sale/listings/](https://www.truecar.com/used-cars-for-sale/listings/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "V1SHRuOC0xyp",
    "outputId": "60e45d40-541b-46b2-aad6-bd2f3f0a7b4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_listings = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"true_car_listings.csv\")\n",
    "type(vehicle_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjpkPAwR0xyq"
   },
   "source": [
    "## Validating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fFnuOYP0xyq"
   },
   "source": [
    "Now that the data is available as a local *dataframe* on the Spark cluster, let's validate the dataframe by look at the schema, size, samples and statistics of our working data - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PAM9opno0xyr",
    "outputId": "8d1bebb3-6c42-4a3d-958b-9deb411dc132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Price: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Mileage: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Vin: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vehicle_listings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yz-uQbBn0xys"
   },
   "source": [
    "Dimensions of Raw Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8-zlWApr0xyt",
    "outputId": "fe1b18a2-5905-4dd5-96d1-badb821ecede",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852122 8\n"
     ]
    }
   ],
   "source": [
    "print(vehicle_listings.count(),len(vehicle_listings.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUGejg6w0xyt"
   },
   "source": [
    "Collecting random sample to see what kind of data populates each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IiCvv0Lx0xyu",
    "outputId": "c8b865f4-bf1f-4a5d-a173-18e732446a31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Vin</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>10495</td>\n",
       "      <td>2012</td>\n",
       "      <td>95187</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>WI</td>\n",
       "      <td>1VWCH7A31CC061218</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Passat4dr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6900</td>\n",
       "      <td>2005</td>\n",
       "      <td>82100</td>\n",
       "      <td>OSSEO</td>\n",
       "      <td>MN</td>\n",
       "      <td>JH4DC54845S011549</td>\n",
       "      <td>Acura</td>\n",
       "      <td>RSXAutomatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>16678</td>\n",
       "      <td>2015</td>\n",
       "      <td>26578</td>\n",
       "      <td>Kendall</td>\n",
       "      <td>FL</td>\n",
       "      <td>KNMAT2MT9FP589013</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>RogueS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38899</td>\n",
       "      <td>2017</td>\n",
       "      <td>9985</td>\n",
       "      <td>Beavercreek</td>\n",
       "      <td>OH</td>\n",
       "      <td>5GAKVCKD1HJ159449</td>\n",
       "      <td>Buick</td>\n",
       "      <td>EnclavePremium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10950</td>\n",
       "      <td>2012</td>\n",
       "      <td>77611</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>1FAHP3N22CL464474</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Focus5dr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>12668</td>\n",
       "      <td>2014</td>\n",
       "      <td>80216</td>\n",
       "      <td>Newburgh</td>\n",
       "      <td>NY</td>\n",
       "      <td>JN8AS5MV6EW700390</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>Rogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>11565</td>\n",
       "      <td>2006</td>\n",
       "      <td>148144</td>\n",
       "      <td>Brownsville</td>\n",
       "      <td>TX</td>\n",
       "      <td>1FTPW14V66KC91335</td>\n",
       "      <td>Ford</td>\n",
       "      <td>F-1504WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46900</td>\n",
       "      <td>2017</td>\n",
       "      <td>4699</td>\n",
       "      <td>Concord</td>\n",
       "      <td>CA</td>\n",
       "      <td>5UXWX9C35H0W68516</td>\n",
       "      <td>BMW</td>\n",
       "      <td>X3xDrive28i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>40990</td>\n",
       "      <td>2016</td>\n",
       "      <td>9713</td>\n",
       "      <td>Katy</td>\n",
       "      <td>TX</td>\n",
       "      <td>5TFDW5F15GX556304</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Tundra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46775</td>\n",
       "      <td>2015</td>\n",
       "      <td>24895</td>\n",
       "      <td>Puyallup</td>\n",
       "      <td>WA</td>\n",
       "      <td>1FTEW1EG6FFB70501</td>\n",
       "      <td>Ford</td>\n",
       "      <td>F-1504WD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Year Mileage         City State                Vin        Make  \\\n",
       "90  10495  2012   95187     Franklin    WI  1VWCH7A31CC061218  Volkswagen   \n",
       "0    6900  2005   82100        OSSEO    MN  JH4DC54845S011549       Acura   \n",
       "71  16678  2015   26578      Kendall    FL  KNMAT2MT9FP589013      Nissan   \n",
       "8   38899  2017    9985  Beavercreek    OH  5GAKVCKD1HJ159449       Buick   \n",
       "30  10950  2012   77611      Houston    TX  1FAHP3N22CL464474        Ford   \n",
       "68  12668  2014   80216     Newburgh    NY  JN8AS5MV6EW700390      Nissan   \n",
       "33  11565  2006  148144  Brownsville    TX  1FTPW14V66KC91335        Ford   \n",
       "4   46900  2017    4699      Concord    CA  5UXWX9C35H0W68516         BMW   \n",
       "88  40990  2016    9713         Katy    TX  5TFDW5F15GX556304      Toyota   \n",
       "35  46775  2015   24895     Puyallup    WA  1FTEW1EG6FFB70501        Ford   \n",
       "\n",
       "             Model  \n",
       "90       Passat4dr  \n",
       "0     RSXAutomatic  \n",
       "71          RogueS  \n",
       "8   EnclavePremium  \n",
       "30        Focus5dr  \n",
       "68           Rogue  \n",
       "33        F-1504WD  \n",
       "4      X3xDrive28i  \n",
       "88          Tundra  \n",
       "35        F-1504WD  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_listings.sample(False,0.0001,10).toPandas().sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa8Q35k40xyv"
   },
   "source": [
    "Basic statistics on raw dataset columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nYz6aGHW0xyv",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------+------+-----------------+\n",
      "|summary|             Price|              Year|       City| State|              Vin|\n",
      "+-------+------------------+------------------+-----------+------+-----------------+\n",
      "|  count|            852122|            852122|     852122|852122|           852122|\n",
      "|   mean| 21464.10020982911|2013.2891452162953|       null|  null|             69.0|\n",
      "| stddev|13596.202240557528| 3.414987035747542|       null|  null|             null|\n",
      "|    min|             10000|              1997|      AKRON|    AK|04WT3N56GG0646582|\n",
      "|    max|             99999|              2018|victorville|    ga|ZN661YUS9HX226976|\n",
      "+-------+------------------+------------------+-----------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Example:\n",
    "vehicle_listings.select(\"Price\",\"Year\",\"City\",\"State\",\"Vin\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQ3UBN0X0xyw"
   },
   "source": [
    "Generally, the `.describe()` or `.explain()` method is a good way to start exploring a dataset. For this dataset, there are too many columns, some very unclean, and it is hard to decipher much from the above results. <br>\n",
    "\n",
    "For this project, we will perform cleaning twice. The Extract stage has a basic cleaning section to remove duplicates and to obtain numerical features (notice in the schema above, all columns are *String* by default). We can cache the Extracted Data in a compressed format such as parquet, so it can be used for different pipelines. <br>\n",
    "\n",
    "The main cleaning section is performed during the [Transform Stage](#Transform-Data).<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB2oO53J0xyx"
   },
   "source": [
    "## Cleaning Data (Basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08oRRyw90xyx"
   },
   "source": [
    "The goal of **Extract Stage** cleaning is to find a balance between cleaning the data and maintaining the maximum amount of raw data. This optimizes usability for other pipelines. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoTbFQw50xyy"
   },
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWMmw9q20xyy"
   },
   "source": [
    "The raw dataset was obtained using a scraper from truecar. This means that each post will have a unique url. Print the URL count and duplicate url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqANeVlS0xy0"
   },
   "source": [
    "The scraper can't find duplicate recors because of various reasons. Each duplicate is more likely the result of people posting multiple times or other errors. Therefore no record from the raw dataset can be found to be a complete duplicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFp_pR6I0xy1"
   },
   "source": [
    "However, duplicates can be removed by excluding `url` when calling .drop_duplicates() on **`vehicle_listings`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7fmTky6a0xy2",
    "outputId": "aa28d5e7-2aaf-45e6-b043-060a5c5bd49b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Price', 'Year', 'Mileage', 'City', 'State', 'Vin', 'Make', 'Model']\n"
     ]
    }
   ],
   "source": [
    "print(vehicle_listings.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8qvCi4b70xy2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Price: string, Year: string, Mileage: string, City: string, State: string, Vin: string, Make: string, Model: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop Duplicates here using the above drop_duplicated() Function\n",
    "vehicle_listings.drop_duplicates(['Price', 'Year', 'Mileage', 'City', 'State', 'Vin', 'Make', 'Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20mXU-UI0xy3"
   },
   "source": [
    "### Obtain Numerical Columns\n",
    "Convert *numerical feature types* from string to float to obtain **Numerical** data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dxlEsc0G3cwq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Price: float (nullable = true)\n",
      " |-- Year: float (nullable = true)\n",
      " |-- Mileage: float (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Vin: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Write Your Code here!\n",
    "cols=[\"Price\",\"Year\",\"Mileage\"]\n",
    "\n",
    "vehicle_listings_clean = (reduce(\n",
    "            lambda memo_df, col_name: memo_df.withColumn(col_name, vehicle_listings[col_name].cast(\"float\")),\n",
    "            cols,\n",
    "            vehicle_listings))\n",
    "\n",
    "vehicle_listings_clean.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzu-7kdx0xy5"
   },
   "source": [
    "## Caching Extract Data on S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRMF-Hx70xy5"
   },
   "source": [
    "After cleaning, the final task in the **Extract** stage is to cache the data. I will store the cleaned dataset as a parquet file on Amazon S3. We can return to this file without having to run the Extract pipeline again, and attach other pipelines from this point as well. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulNlqBpk0xy6"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>NOTE</b> This implementation uses .coalesce(4) before .write() to optimize read/write performance on S3.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QPW3u-hU0xy6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#vehicle_listings_clean.write.parquet(\"s3a://yasin/usedcars/extract\",mode=\"overwrite\")\n",
    "vehicle_listings_clean.coalesce(4).write.parquet(\"vehicle_listings_extract.parquet\",mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuqRn5dv0xy7"
   },
   "source": [
    "Unable to connect to S3 directly using SparkSession due to Spark generating its credentials, possibly due to versioning... <br>\n",
    "Instead, we can connect to S3 using a bash script.<br>\n",
    "The parquet compression brings the file size down to *<30MB*, so this doesn't cause performance issues here.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivmHqGzB0xy7",
    "outputId": "c9bcc080-80b0-448a-a369-682aaa41f66e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to AWS S3...\n",
      "Object Written to S3.\n"
     ]
    }
   ],
   "source": [
    "print (\"Connecting to AWS S3...\")\n",
    "subprocess.Popen(['./S3_connect.command','write_extract'])\n",
    "print (\"Object Written to S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8D4BJqL0xy8"
   },
   "source": [
    "This completes the **Extract Stage**. <br>\n",
    "\n",
    "We clean, sample and explore the data in the **Transform Stage**. The data available on S3 is clean but as close to the raw data as possible. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxpSru6d0xy9"
   },
   "source": [
    "# Transform Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cgx7tem60xy9"
   },
   "source": [
    "*First we obtain the working dataset from the cached source on S3.* <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mF_vFNhY0xy-",
    "outputId": "f18216e5-2122-4d29-fb87-4e4d2fd37c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to AWS S3...\n",
      "Object Read from S3 to ../data.\n"
     ]
    }
   ],
   "source": [
    "print (\"Connecting to AWS S3...\")\n",
    "subprocess.Popen(['./S3_connect.command','read_extract'])\n",
    "print (\"Object Read from S3 to ../data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGUmobOZ0xy-",
    "outputId": "db890883-fc7b-4eb7-96c4-12dffb7984ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vehicles_listings_read=spark.read.parquet(\"s3a://s3://yasin/usedcars/extract\")\n",
    "#vehicle_listings_read=spark.read.parquet(\"../data/vehicle_listings_read.parquet\")\n",
    "\n",
    "vehicle_listings_clean = spark.read.format(\"parquet\").option(\"inferschema\",\"true\").load(\"vehicle_listings_read_extract.parquet\")\n",
    "type(vehicle_listings_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fLnpkA_g0xy_",
    "outputId": "0dbc95d6-ed24-4b44-8792-f0aaf67a9817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852122 8\n"
     ]
    }
   ],
   "source": [
    "print(vehicle_listings_clean.count(),len(vehicle_listings_clean.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgHLbeK-0xzA"
   },
   "source": [
    "There are over 1.5 million records, and 26 columns. The dataset is too large to perform EDA (Exploratory Data Analysis) comfortably. <br>\n",
    "The final data after *Cleaning* should be as clean as possible without redundant data.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zlz9nIh0xzA"
   },
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5HKK7Vo0xzB"
   },
   "source": [
    "Cleaning is essential during the **Transform Stage** of the ETL pipeline. The main goal here is to optimize the dataset for the endgoal of the project - Creating a machine learning pipeline to predict the target varibale **Price**. <br>\n",
    "\n",
    "We can also cache the cleaned data set before sampling and exploration for other machine learning project using the same dataset.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSHWVv6p0xzC"
   },
   "source": [
    "### Cleaning Checkpoints\n",
    "\n",
    "+  General\n",
    "    +  Drop Columns\n",
    "    +  Drop Rows (Null Price)\n",
    "+  Numerical \n",
    "    +  Apply Reasonable Ranges\n",
    "        +  Kept Odometer Null Values\n",
    "+  Ordinal\n",
    "    +  Narrow down relevant options\n",
    "    +  Remove errors in columns\n",
    "    +  Keep countable ordinal values\n",
    "+  Categorical\n",
    "    +  State_code + State_name (Extract Stage)\n",
    "        +  Removed State_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vegb9uVM0xzD"
   },
   "source": [
    "#### Drop Columns\n",
    "\n",
    "Some Columns are redundant, we can remove them before moving forward.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "w4JURF7N0xzE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------+------+-----------------+------+-----------------+\n",
      "|summary|             Price|              Year|       City| State|              Vin|  Make|            Model|\n",
      "+-------+------------------+------------------+-----------+------+-----------------+------+-----------------+\n",
      "|  count|            852122|            852122|     852122|852122|           852122|852122|           852122|\n",
      "|   mean| 21464.10020982911|2013.2891452162953|       null|  null|             69.0|  null|6829.188492490424|\n",
      "| stddev|13596.202240557528| 3.414987035747542|       null|  null|             null|  null|95299.16891308237|\n",
      "|    min|             10000|              1997|      AKRON|    AK|04WT3N56GG0646582|    AM|                1|\n",
      "|    max|             99999|              2018|victorville|    ga|ZN661YUS9HX226976| smart|         xDManual|\n",
      "+-------+------------------+------------------+-----------+------+-----------------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#write your code here!\n",
    "vehicle_listings.select(\"Price\",\"Year\",\"City\",\"State\",\"Vin\",\"Make\",\"Model\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHiwPE1w0xzJ"
   },
   "source": [
    "'lat' and 'long' provide no more useful information than ('city','county_name', 'state_code', 'state_name'), and are therefore not needed.<br>\n",
    "The other dropped columns are not helpful to the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXV5t_Iv0xzJ"
   },
   "source": [
    "The remaining attribute characteristics are varied, we have three types of features available in our data -\n",
    "**Numerical**, **Ordinal**, **Categorical**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRqV92zh0xzK"
   },
   "source": [
    "**Potential Column Types -** <br>\n",
    "Numerical - price, year, odometer <br>\n",
    "Ordinal - condition, cylinders, fuel, title_status, transmission, drive, size, type <br>\n",
    "Categorical - city, manufacturer, make, county_name, state_code, state_name <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE7wMR5Q0xzK"
   },
   "source": [
    "The target variable of this project is **Price**. Therefore, any records where price is null would be irrelevant. Check to see if the dataset contains null prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "idXzNOE00xzK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write your code here!\n",
    "vehicle_listings_clean.filter(vehicle_listings_clean.Price.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpqrEHA70xzL"
   },
   "source": [
    "### Numerical Data Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "y02MuTtA0xzL"
   },
   "outputs": [],
   "source": [
    "# Make Smaller subset to take quick look at records\n",
    "Num=[\"Price\",\"Year\",\"Mileage\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_P8-AQy0xzM"
   },
   "source": [
    "#### Applying a Reasonable Range on Continuous Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpjxT90X0xzM"
   },
   "source": [
    "Website postings that advertise items for sale often manipulate search algorithms to get more hits. For example, thousands of posts are spammed with a price of $1 (minimum allowed), to get more visibility through the 'search by price' filter. To ensure that our working dataset is within reasonable boundaries, we apply restrictions on the *Continuous* data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FNm9oIZY0xzN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data: 0\n",
      "Old data: 0\n",
      "Expensive cars: 91\n",
      "Cheap cars: 0\n",
      "Many mileage: 624342\n",
      "few mileage: 3830\n"
     ]
    }
   ],
   "source": [
    "#write your code here!\n",
    "print(\"New data: %d\" %vehicle_listings_clean.where(\"Year >= 2019\").count())\n",
    "print(\"Old data: %d\" %vehicle_listings_clean.where(\"Year < 1930\").count())\n",
    "print(\"Expensive cars: %d\" %vehicle_listings_clean.where(\"Price > 300000\").count())\n",
    "print(\"Cheap cars: %d\" %vehicle_listings_clean.where(\"Price < 50\").count())\n",
    "print(\"Many mileage: %d\" %vehicle_listings_clean.where(\"Mileage > 25000\").count())\n",
    "print(\"few mileage: %d\" %vehicle_listings_clean.where(\"Mileage < 50\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJX9DZ6L0xzO"
   },
   "source": [
    "Before removing 20k+ records due to price, let's confirm if the spame hypothesis is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6Y0kPF1N0xzO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------+\n",
      "|Price|Year|Mileage|\n",
      "+-----+----+-------+\n",
      "+-----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#write your code here!\n",
    "vehicle_listings_clean.sample(False,0.001,100).where(\"Price<50\").select(Num).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt1kJ-PI0xzP"
   },
   "source": [
    "As expected, these randomly obtained results show us that \"price<50\" is not very useful to the study. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mising values of Mileage: 0\n",
      "Missing values Price : 0\n",
      "Missing values of  Year : 0\n"
     ]
    }
   ],
   "source": [
    "#Write your code here!\n",
    "print(\"Mising values of Mileage:\",vehicle_listings_clean.filter(vehicle_listings_clean.Mileage.isNull()).count())\n",
    "print(\"Missing values Price :\",vehicle_listings_clean.filter(vehicle_listings_clean.Price.isNull()).count())\n",
    "print(\"Missing values of  Year :\",vehicle_listings_clean.filter(vehicle_listings_clean.Year.isNull()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zEF0CkW0xzQ"
   },
   "source": [
    "The Null counts shows us that a lot of listings have not reported Odometer values, perhaps to increase chances of selling a car or maybe due to lack of info. The question is, do we remove all these records altogether?<br>\n",
    "I would rather keep these records because the 50k+ rows will still provide useful information about other attributes. Removing these values would reduce the dataset by 35%, which is too high.<br>\n",
    "<br>Apply the restrictions to vehicle_listings_clean.<br>\n",
    "Note- The Spark environment allows me to use a direct SQL query to restrict odometer values. This is better suited because the **`pyspark.sql.dataframe`** library treats \"null\" values as false when evaluating the `.where()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "I9E1QLoF0xzQ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\spark-3.2.1-bin-hadoop2.7\\spark-3.2.1-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original dataset  852122\n",
      "range  846912\n",
      " 99 percent number of data stored\n",
      "+-------+------------------+------------------+-----------------+\n",
      "|summary|             Price|              Year|          Mileage|\n",
      "+-------+------------------+------------------+-----------------+\n",
      "|  count|            846912|            846912|           846912|\n",
      "|   mean|  21396.6219040467|2013.2876473588756|52345.84431676491|\n",
      "| stddev|13048.694725871834|3.3955512601171827|40034.19026960797|\n",
      "|    min|            1500.0|            1997.0|             50.0|\n",
      "|    max|          299999.0|            2018.0|         250000.0|\n",
      "+-------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#write your code here!\n",
    "vehicle_listings_clean = vehicle_listings_clean.where(\"Price>=50 and Price<=300000\").where(\"Year>=1930 and Year<2019\") \n",
    "\n",
    "vehicle_listings_clean.registerTempTable(\"df_temp\")\n",
    "\n",
    "vehicle_listings_clean=spark.sql(\"SELECT * FROM df_temp WHERE (Mileage>=50 AND Mileage<=250000) OR (Mileage IS NULL)\")\n",
    "\n",
    "main=vehicle_listings.count()\n",
    "recent=vehicle_listings_clean.count()\n",
    "\n",
    "print(\"Number of original dataset \",main)\n",
    "print(\"range \",recent)\n",
    "print(\" %d percent number of data stored\" % (100 * recent / main))\n",
    "\n",
    "vehicle_listings_clean.select(\"Price\",\"Year\",\"Mileage\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tgFZjZS0xzR"
   },
   "source": [
    "Although only 3 attributes, **price, year, odometer**, can be directly converted to numerical value, other attributes can be be transformed to fit the Categorical and Ordinal labels. The difference between categorical and ordinal values is that ordinal values have a clear and restricted ordering of types. For example, *'condition'* would be ordinal, ranging from excellent to poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izae2C1Y0xzR"
   },
   "source": [
    "### Ordinal Data Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDYozlpq0xzS"
   },
   "source": [
    "Ordinal data will play an important role in learning about price. An ordinal data type is a variable that has a limited number of options, which can be ordered. For example, `\"condition\"` should range from excellent to bad (or in this case, \"salvage\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivz-0ciZ0xzS"
   },
   "source": [
    "The following columns are of the **Ordinal** types -  <br>\n",
    "(condition, cylinders, fuel, title_status, transmission, drive, size, type) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5kU8RGq0xzT"
   },
   "source": [
    "**`ordinals_options_all`** is a map linking each ordinal to each distinct value provided for it. This will help cleaning the dataset faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "pszM94GY0xzT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Price: float, Year: float, Mileage: float, City: string, State: string, Vin: string, Make: string, Model: string]\n"
     ]
    }
   ],
   "source": [
    "#writw your code here\n",
    "ordcolumns=vehicle_listings_clean['Price', 'Year', 'Mileage', 'City', 'State', 'Vin', 'Make', 'Model']\n",
    "print(ordcolumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eqgHm9v0xzU"
   },
   "source": [
    "As expected, all 8 Ordinal columns have values that seem to be errors, or reported incorrectly. For example, let's look into the \"Condition\" reported as 'audio controls\"'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------+-----+\n",
      "|Price|Year|Mileage|Model|\n",
      "+-----+----+-------+-----+\n",
      "+-----+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#write your code here!\n",
    "vehicle_listings_clean.filter(\"Model = 'Tundra\\\"'\" ).select(Num+[\"Model\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvz4Yfbv0xzV"
   },
   "source": [
    "Only 1 record fetched. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hluO6T9_0xzV"
   },
   "source": [
    "The next task is to clean these misleading values for each of the ordinal types. Automating this process, at the very least requires two `pyspark.sql.dataframe` library calls for each distinct ordinal option - `count()` and `replace()`. We can count the number of occurences of a value in an ordinal column, if it's less than 10 then it is  irrelevant and will be grouped under \"other\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ady0Vu5R0xzW"
   },
   "source": [
    "**`remove_fakes()`** is a function that takes in a column and all distinct values within the column, and evaluates which options are useful. It bunches up other options under \"Other\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_tk7F9h0xzW"
   },
   "source": [
    "Time Cost - Each call to **`remove_fakes()`** will take **O(n)** *(O(2n+1))* where *n* is the length of the column. Because the algorithm needs to call both `count()` and `replace()` for any ordinal/value combination, this is the fastest way to clean the ordinal columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "BBCK32Tl0xzX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717\n"
     ]
    }
   ],
   "source": [
    "#write your code here\n",
    "print(vehicle_listings_clean.select(\"Model\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPQVfdUC0xzX"
   },
   "source": [
    "The above function does not count *null* values. The difference between values printed as a list after the clean versus the final `count()` value are *null* and, in some cases, *other*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvMfFjGr0xzY"
   },
   "source": [
    "#### Cleaning column = 'condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "5XKbbhPC0xzY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for price 46715\n"
     ]
    }
   ],
   "source": [
    "#write your code here for Price\n",
    "print(\"Number for price\",vehicle_listings_clean.select(\"Price\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDKLysTJ0xzY"
   },
   "source": [
    "#### Cleaning column = 'cylinders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "vpCUjl4b0xzZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for year 22\n"
     ]
    }
   ],
   "source": [
    "#write your code here for Year\n",
    "print(\"Number for year\",vehicle_listings_clean.select(\"Year\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuv3fhYp0xza"
   },
   "source": [
    "#### Cleaning column = 'fuel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "rUkNfaqo0xzb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for Mileage 157547\n"
     ]
    }
   ],
   "source": [
    "#write your code here for Mileage\n",
    "print(\"Number for Mileage\",vehicle_listings_clean.select(\"Mileage\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT7zqSTh0xzc"
   },
   "source": [
    "#### Cleaning column = 'title_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "KlSFOmco0xzc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for City 2553\n"
     ]
    }
   ],
   "source": [
    "#write your code here for City\n",
    "print(\"Number for City\",vehicle_listings_clean.select(\"City\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZpSs7860xzd"
   },
   "source": [
    "#### Cleaning column = 'transmission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "sNDazzqK0xzd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for State 59\n"
     ]
    }
   ],
   "source": [
    "#write your code here State\n",
    "print(\"Number for State\",vehicle_listings_clean.select(\"State\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2f5tGy80xzf"
   },
   "source": [
    "#### Cleaning column = 'drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "UMYc6th10xzf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for Vin 846865\n"
     ]
    }
   ],
   "source": [
    "#write your code here Vin\n",
    "print(\"Number for Vin\",vehicle_listings_clean.select(\"Vin\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciAKE_iy0xzg"
   },
   "source": [
    "#### Cleaning column = 'size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "87blQEzc0xzg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for Make 58\n"
     ]
    }
   ],
   "source": [
    "#write your code here Make\n",
    "print(\"Number for Make\",vehicle_listings_clean.select(\"Make\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QtwLNhc0xzh"
   },
   "source": [
    "#### Cleaning column = 'type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "FyS47bpx0xzi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number for Model 2717\n"
     ]
    }
   ],
   "source": [
    "#write your code here Model\n",
    "print(\"Number for Model\",vehicle_listings_clean.select(\"Model\").distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ASkoNav0xzj"
   },
   "source": [
    "### Categorical Data Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzqWiRt80xzk"
   },
   "source": [
    "Categorical - city, manufacturer, make, county_name, state_code, state_name <br>\n",
    "\n",
    "During the **Transform** stage, categorical columns will help with *Stratified Sampling* before beginning with Exploratory Data Analysis... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STw2QU100xzk"
   },
   "source": [
    "There isn't much cleaning to be done with categorical data. An easy observation is that this set of columns give us insight about location unlike other column types. There might be a way to combine state_code and state_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "pl0ob07w0xzl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|           City|State|\n",
      "+---------------+-----+\n",
      "|       Kirkland|   WA|\n",
      "|   Morton Grove|   IL|\n",
      "|         Tacoma|   WA|\n",
      "|     Carrollton|   TX|\n",
      "|     Louisville|   KY|\n",
      "|      Westfield|   IN|\n",
      "|       Columbia|   MO|\n",
      "|Fort Lauderdale|   FL|\n",
      "|        Concord|   NC|\n",
      "|          Havre|   MT|\n",
      "|        Fairfax|   VA|\n",
      "|          Davie|   FL|\n",
      "|        Houston|   TX|\n",
      "|      Bethlehem|   PA|\n",
      "| East Greenwich|   RI|\n",
      "|       Wartburg|   TN|\n",
      "|      Las Vegas|   NV|\n",
      "|         Athens|   OH|\n",
      "|        Houston|   TX|\n",
      "|     Hackensack|   NJ|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#write your code here\n",
    "vehicle_listings_clean.select(\"City\",\"State\").sample(False,0.0001,100).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXdHuT2S0xzl"
   },
   "source": [
    "We can see that when state_code is *null*, the matching state_name is *Failed*. Since the state_name appears to be generated by state_code, there isn't any point in keeping both. Let's remove state_name. Our total columns are now 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original =  852122 * 8\n",
      "New =  846912 * 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Original = \",vehicle_listings.count(),\"*\",len(vehicle_listings.columns))\n",
    "print(\"New = \",vehicle_listings_clean.count(),\"*\",len(vehicle_listings_clean.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8o68VrOh0xzn"
   },
   "source": [
    "#### Final dataset size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "fLjE29yM0xzn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dimensions =  852122 * 8\n",
      "New Dimensions =  846912 * 8\n",
      "Data kept for analysis: 99 percent of records\n"
     ]
    }
   ],
   "source": [
    "#write your code here\n",
    "old_col=vehicle_listings.count()\n",
    "old_row=len(vehicle_listings.columns)\n",
    "new_col=vehicle_listings_clean.count()\n",
    "new_row=len(vehicle_listings_clean.columns)\n",
    "\n",
    "print(\"Original Dimensions = \",old_col,\"*\",old_row)\n",
    "print(\"New Dimensions = \",new_col,\"*\",new_row)\n",
    "\n",
    "\n",
    "print(\"Data kept for analysis: %d percent of records\" % (100 * new_col / old_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJYjHRU80xzo"
   },
   "source": [
    "The used cars dataset is now cleaned and ready for analysis. We can cache this version on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhoWOMmO0xzo"
   },
   "outputs": [],
   "source": [
    "#vehicle_listings_clean.write.parquet(\"s3a://deveshetl/usedcars/transform\",mode=\"overwrite\")\n",
    "vehicle_listings_clean.coalesce(4).write.parquet(\"vehicle_listings_transform.parquet\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6ffWnqQ0xzp",
    "outputId": "0a4b9e89-10b0-419c-af63-ee3ca7bdd293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to AWS S3...\n",
      "Object Written to S3.\n"
     ]
    }
   ],
   "source": [
    "print (\"Connecting to AWS S3...\")\n",
    "subprocess.Popen(['./S3_connect.command','write_transform'])\n",
    "print (\"Object Written to S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ijh_n_T0xzp"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOa5mQ5X0xzq"
   },
   "source": [
    "*First we obtain the working dataset from the cached source on S3.* <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSG7AvP_0xzr",
    "outputId": "d3ef09a7-6239-40e9-cd70-b67abe438817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to AWS S3...\n",
      "Object Read from S3 to ../data.\n"
     ]
    }
   ],
   "source": [
    "print (\"Connecting to AWS S3...\")\n",
    "subprocess.Popen(['./S3_connect.command','read_transform'])\n",
    "print (\"Object Read from S3 to ../data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqjxkpYW0xzs",
    "outputId": "257bb00e-6d0b-4368-bd6f-74fb8e3a5e28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vehicles_listings_read=spark.read.parquet(\"s3a://s3://yasin/usedcars/extract\")\n",
    "#vehicle_listings_read=spark.read.parquet(\"../data/vehicle_listings_read.parquet\")\n",
    "\n",
    "vehicle_listings_clean = spark.read.format(\"parquet\").option(\"inferschema\",\"true\").load(\"vehicle_listings_read_transform.parquet\")\n",
    "type(vehicle_listings_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "x2fwILZk0xzy",
    "outputId": "52b13d0a-e403-4e90-dfa2-fe55509b87e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846912 8\n"
     ]
    }
   ],
   "source": [
    "print(vehicle_listings_clean.count(),len(vehicle_listings_clean.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMmrDBmx0xz0"
   },
   "source": [
    "In the section, we will obtain features from the ordinal columns, in order to use the information for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ZcRRjr4t0xz0",
    "outputId": "80043e08-c84f-4b20-cbc0-d54bef66eef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Price: float, Year: float, Mileage: float, City: string, State: string, Vin: string, Make: string, Model: string]\n"
     ]
    }
   ],
   "source": [
    "print(ordcolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "6Ue3-2WP0xz1"
   },
   "outputs": [],
   "source": [
    "vehicle_listings_clean = vehicle_listings_clean.fillna({'Price':'other'})\n",
    "vehicle_listings_clean = vehicle_listings_clean.fillna({'Year':'other'})\n",
    "vehicle_listings_clean = vehicle_listings_clean.fillna({'Mileage':'other'})\n",
    "vehicle_listings_clean = vehicle_listings_clean.fillna({'City':'other'})\n",
    "vehicle_listings_clean = vehicle_listings_clean.fillna({'State':'other'})\n",
    "vehicle_listings_clean = vehicle_listings_clean.fillna({'Vin':'other'})\n",
    "vehicle_listings_clean = vehicle_listings_clean.fillna({'Make':'other'})\n",
    "vehicle_listings_clean = vehicle_listings_clean.fillna({'Model':'other'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtkCVcTI0xz2"
   },
   "source": [
    "### String Indexer\n",
    "\n",
    "Using `StringIndexer`, convert ordinal column names to numerical values. It is import to retain the original columns track which index is assigned to which unique column option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "eX8Uiy020xz2"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\")\\\n",
    "            .setHandleInvalid(\"skip\")\\\n",
    "            .fit(vehicle_listings_clean) for column in ordcolumns]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "vehicle_listings_features = pipeline.fit(vehicle_listings_clean).transform(vehicle_listings_clean)\n",
    "\"\"\"\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    StringIndexer(inputCol=c, outputCol='{}_index'.format(c))\n",
    "    for c in vehicle_listings_clean.columns\n",
    "])\n",
    "\n",
    "vehicle_listings_features = pipeline.fit(vehicle_listings_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "EKMzmvb50xz3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Price: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Mileage: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Vin: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Price='8995', Year='2014', Mileage='35725', City='El Paso', State=' TX', Vin='19VDE2E53EE000083', Make='Acura', Model='ILX6-Speed'),\n",
       " Row(Price='10888', Year='2013', Mileage='19606', City='Long Island City', State=' NY', Vin='19VDE1F52DE012636', Make='Acura', Model='ILX5-Speed'),\n",
       " Row(Price='8995', Year='2013', Mileage='48851', City='El Paso', State=' TX', Vin='19VDE2E52DE000025', Make='Acura', Model='ILX6-Speed')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vehicle_listings.printSchema())\n",
    "vehicle_listings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "cE4T6wm_0xz7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852122 8\n"
     ]
    }
   ],
   "source": [
    "print(vehicle_listings.count(),len(vehicle_listings.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltrLIl880xz8"
   },
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "Using `OneHotEncoderEstimator`, we can encode the ordinal column indexes.\n",
    "\n",
    "One-hot encoding maps a categorical feature, represented as a label index, to a binary vector with at most a single one-value indicating the presence of a specific feature value from among the set of all feature values. This encoding allows algorithms which expect continuous features, such as Logistic Regression, to use categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "bc7FlNUX0xz8"
   },
   "outputs": [],
   "source": [
    "#write your code here\n",
    "vehicle_listings_encoded = Pipeline(stages=[\n",
    "   OneHotEncoder(inputCol=c, outputCol='{}_index'.format(c))\n",
    "    for c in vehicle_listings_clean.columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "cLEFIyjU0xz9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Price: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Mileage: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Vin: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vehicle_listings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuNjdaxw0xz9"
   },
   "source": [
    "The new 8 columms of `vehicle_listings_encoded` are of type `vector`. This type can be recognized by Machine Learning models, so there is not need to extract each vector into separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBiF58Mg0xz-",
    "outputId": "2e858252-fe84-478c-b89e-cc7eb82503a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1470500 32\n"
     ]
    }
   ],
   "source": [
    "print(vehicle_listings_encoded.count(),len(vehicle_listings_encoded.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMfbaAwy0x0A"
   },
   "source": [
    "## Sampling Data\n",
    "\n",
    "<br>To explore the dataset for analysis, create a **sample pandas dataframe** from the engineered data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "VUk27DcY0x0B"
   },
   "outputs": [],
   "source": [
    "#write your code here\n",
    "eda_df=vehicle_listings_clean.sample(False,0.001,63).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5Iqc26y0x0B"
   },
   "source": [
    "With a small random sample of the Feature Engineered Data, we can take a look at what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "l05PsDzL0x0C"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Vin</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>17799.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9895.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>KMHTC6AE1GU273805</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>VelosterAutomatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>17320.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>14910.0</td>\n",
       "      <td>Port Richey</td>\n",
       "      <td>FL</td>\n",
       "      <td>3FA6P0H78HR117544</td>\n",
       "      <td>Ford</td>\n",
       "      <td>FusionSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>33797.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>27037.0</td>\n",
       "      <td>Mission Viejo</td>\n",
       "      <td>CA</td>\n",
       "      <td>2T2ZK1BA9FC167478</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>RX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>6995.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>97038.0</td>\n",
       "      <td>Chantilly</td>\n",
       "      <td>VA</td>\n",
       "      <td>5NPEB4ACXBH143074</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Sonata4dr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>101866.0</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>JF1GD61657G521361</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Impreza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>17500.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>6713.0</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>KY</td>\n",
       "      <td>4A4AP4AW7FE041739</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>Outlander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>77880.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>15804.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>1FT7W2BT7HEC04096</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>18997.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>69395.0</td>\n",
       "      <td>Ramsey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>1FTNE2EW9CDB13412</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Econoline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>36995.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>8875.0</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>IL</td>\n",
       "      <td>1C6RR7TT2HS646384</td>\n",
       "      <td>Ram</td>\n",
       "      <td>1500SLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>27900.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>64959.0</td>\n",
       "      <td>Pilot Point</td>\n",
       "      <td>TX</td>\n",
       "      <td>1FTFW1ET5EFB84597</td>\n",
       "      <td>Ford</td>\n",
       "      <td>F-1504WD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Price    Year   Mileage           City State                Vin  \\\n",
       "446  17799.0  2016.0    9895.0         Austin    TX  KMHTC6AE1GU273805   \n",
       "236  17320.0  2017.0   14910.0    Port Richey    FL  3FA6P0H78HR117544   \n",
       "536  33797.0  2015.0   27037.0  Mission Viejo    CA  2T2ZK1BA9FC167478   \n",
       "443   6995.0  2011.0   97038.0      Chantilly    VA  5NPEB4ACXBH143074   \n",
       "699   8000.0  2007.0  101866.0       Pasadena    CA  JF1GD61657G521361   \n",
       "589  17500.0  2015.0    6713.0     Louisville    KY  4A4AP4AW7FE041739   \n",
       "332  77880.0  2017.0   15804.0         Austin    TX  1FT7W2BT7HEC04096   \n",
       "321  18997.0  2012.0   69395.0         Ramsey    NJ  1FTNE2EW9CDB13412   \n",
       "681  36995.0  2017.0    8875.0   Jacksonville    IL  1C6RR7TT2HS646384   \n",
       "322  27900.0  2014.0   64959.0    Pilot Point    TX  1FTFW1ET5EFB84597   \n",
       "\n",
       "           Make              Model  \n",
       "446     Hyundai  VelosterAutomatic  \n",
       "236        Ford           FusionSE  \n",
       "536       Lexus                 RX  \n",
       "443     Hyundai          Sonata4dr  \n",
       "699      Subaru            Impreza  \n",
       "589  Mitsubishi          Outlander  \n",
       "332        Ford              Super  \n",
       "321        Ford          Econoline  \n",
       "681         Ram            1500SLT  \n",
       "322        Ford           F-1504WD  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write your code here\n",
    "eda_df.sample(n=10,replace=False,random_state=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "3t7moxDg0x0D",
    "outputId": "d76d00ca-7596-4eb5-fada-c44892dd056b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price      float32\n",
       "Year       float32\n",
       "Mileage    float32\n",
       "City        object\n",
       "State       object\n",
       "Vin         object\n",
       "Make        object\n",
       "Model       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PySpark Vehicles.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
